{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from shutil import copyfile\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete later\n",
    "import traci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import Simulation, TrainSimulation, VanillaTrainSimulation, RNNTrainSimulation\n",
    "from generator import TrafficGenerator\n",
    "from memory import Memory, NormalMemory, SequenceMemory\n",
    "# from model import TrainModel\n",
    "from model import *\n",
    "from visualization import Visualization\n",
    "from utils import import_train_configuration, set_sumo, set_train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_with_LSTM\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 10, 8, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 5, 4, 3 288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 3, 2, 6 8256        time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 5)      0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 3, 2, 3 8224        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, None, 10)     60          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 192)    0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 202)    0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 96)     114816      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 32)     3104        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 16)     528         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 4)      68          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 135,344\n",
      "Trainable params: 135,344\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      " \n",
      "Starting...\n",
      " \n",
      "\n",
      "----- Episode 1 of 300\n",
      "Simulating...\n",
      "Total reward: -4243.985632073876 - Epsilon: 1.0\n",
      "Training...\n",
      "Simulation time: 4.2 s - Training time: 252.2 s - Total: 256.4 s\n",
      "\n",
      "----- Episode 2 of 300\n",
      "Simulating...\n",
      "Total reward: -66202.07600940252 - Epsilon: 1.0\n",
      "Training...\n",
      "Simulation time: 31.1 s - Training time: 250.1 s - Total: 281.2 s\n",
      "\n",
      "----- Episode 3 of 300\n",
      "Simulating...\n",
      "Total reward: -2835721.43566777 - Epsilon: 0.99\n",
      "Training...\n",
      "Simulation time: 424.4 s - Training time: 262.5 s - Total: 686.9 s\n",
      "\n",
      "----- Episode 4 of 300\n",
      "Simulating...\n",
      "Total reward: -4074507.426828411 - Epsilon: 0.99\n",
      "Training...\n",
      "Simulation time: 474.1 s - Training time: 244.9 s - Total: 719.0 s\n",
      "\n",
      "----- Episode 5 of 300\n",
      "Simulating...\n",
      "Total reward: -481151.1903433391 - Epsilon: 0.99\n",
      "Training...\n",
      "Simulation time: 101.8 s - Training time: 247.6 s - Total: 349.4 s\n",
      "\n",
      "----- Episode 6 of 300\n",
      "Simulating...\n",
      "Total reward: -716378.0182475282 - Epsilon: 0.98\n",
      "Training...\n",
      "Simulation time: 126.4 s - Training time: 245.2 s - Total: 371.6 s\n",
      "\n",
      "----- Episode 7 of 300\n",
      "Simulating...\n",
      "Total reward: -911520.9815214933 - Epsilon: 0.98\n",
      "Training...\n",
      "Simulation time: 181.6 s - Training time: 248.8 s - Total: 430.4 s\n",
      "\n",
      "----- Episode 8 of 300\n",
      "Simulating...\n",
      "Total reward: -1456464.8967867647 - Epsilon: 0.98\n",
      "Training...\n",
      "Simulation time: 242.3 s - Training time: 244.2 s - Total: 486.5 s\n",
      "\n",
      "----- Episode 9 of 300\n",
      "Simulating...\n",
      "Total reward: -3710.096033399797 - Epsilon: 0.97\n",
      "Training...\n",
      "Simulation time: 4.2 s - Training time: 247.8 s - Total: 252.0 s\n",
      "\n",
      "----- Episode 10 of 300\n",
      "Simulating...\n",
      "Total reward: -118120.69364964499 - Epsilon: 0.97\n",
      "Training...\n",
      "Simulation time: 38.5 s - Training time: 246.0 s - Total: 284.5 s\n",
      "\n",
      "----- Episode 11 of 300\n",
      "Simulating...\n",
      "Total reward: -2803868.3794402066 - Epsilon: 0.97\n",
      "Training...\n",
      "Simulation time: 409.8 s - Training time: 246.2 s - Total: 656.0 s\n",
      "\n",
      "----- Episode 12 of 300\n",
      "Simulating...\n",
      "Total reward: -3957629.316942578 - Epsilon: 0.96\n",
      "Training...\n",
      "Simulation time: 472.2 s - Training time: 243.7 s - Total: 715.9 s\n",
      "\n",
      "----- Episode 13 of 300\n",
      "Simulating...\n",
      "Total reward: -522011.9993078774 - Epsilon: 0.96\n",
      "Training...\n",
      "Simulation time: 112.8 s - Training time: 247.1 s - Total: 359.9 s\n",
      "\n",
      "----- Episode 14 of 300\n",
      "Simulating...\n",
      "Total reward: -428252.3593543928 - Epsilon: 0.96\n",
      "Training...\n",
      "Simulation time: 89.7 s - Training time: 249.6 s - Total: 339.3 s\n",
      "\n",
      "----- Episode 15 of 300\n",
      "Simulating...\n",
      "Total reward: -1077185.783928015 - Epsilon: 0.95\n",
      "Training...\n",
      "Simulation time: 197.5 s - Training time: 246.2 s - Total: 443.7 s\n",
      "\n",
      "----- Episode 16 of 300\n",
      "Simulating...\n",
      "Total reward: -934695.6311223934 - Epsilon: 0.95\n",
      "Training...\n",
      "Simulation time: 186.6 s - Training time: 245.7 s - Total: 432.3 s\n",
      "\n",
      "----- Episode 17 of 300\n",
      "Simulating...\n",
      "Total reward: -3245.733304360296 - Epsilon: 0.95\n",
      "Training...\n",
      "Simulation time: 4.9 s - Training time: 247.6 s - Total: 252.5 s\n",
      "\n",
      "----- Episode 18 of 300\n",
      "Simulating...\n",
      "Total reward: -93043.0298125809 - Epsilon: 0.94\n",
      "Training...\n",
      "Simulation time: 35.1 s - Training time: 248.5 s - Total: 283.6 s\n",
      "\n",
      "----- Episode 19 of 300\n",
      "Simulating...\n",
      "Total reward: -2941518.2281665136 - Epsilon: 0.94\n",
      "Training...\n",
      "Simulation time: 422.6 s - Training time: 247.3 s - Total: 669.9 s\n",
      "\n",
      "----- Episode 20 of 300\n",
      "Simulating...\n",
      "Total reward: -3186827.105863155 - Epsilon: 0.94\n",
      "Training...\n",
      "Simulation time: 450.9 s - Training time: 244.1 s - Total: 695.0 s\n",
      "\n",
      "----- Episode 21 of 300\n",
      "Simulating...\n",
      "Total reward: -664448.0660697395 - Epsilon: 0.93\n",
      "Training...\n",
      "Simulation time: 131.2 s - Training time: 248.2 s - Total: 379.4 s\n",
      "\n",
      "----- Episode 22 of 300\n",
      "Simulating...\n",
      "Total reward: -413705.00636892335 - Epsilon: 0.93\n",
      "Training...\n",
      "Simulation time: 84.5 s - Training time: 257.6 s - Total: 342.1 s\n",
      "\n",
      "----- Episode 23 of 300\n",
      "Simulating...\n",
      "Total reward: -1528115.9121683214 - Epsilon: 0.93\n",
      "Training...\n",
      "Simulation time: 251.9 s - Training time: 244.8 s - Total: 496.7 s\n",
      "\n",
      "----- Episode 24 of 300\n",
      "Simulating...\n",
      "Total reward: -1008194.957673632 - Epsilon: 0.92\n",
      "Training...\n",
      "Simulation time: 189.8 s - Training time: 244.5 s - Total: 434.3 s\n",
      "\n",
      "----- Episode 25 of 300\n",
      "Simulating...\n",
      "Total reward: -3307.756961733425 - Epsilon: 0.92\n",
      "Training...\n",
      "Simulation time: 5.3 s - Training time: 247.1 s - Total: 252.4 s\n",
      "\n",
      "----- Episode 26 of 300\n",
      "Simulating...\n",
      "Total reward: -104479.74718151572 - Epsilon: 0.92\n",
      "Training...\n",
      "Simulation time: 36.3 s - Training time: 246.1 s - Total: 282.4 s\n",
      "\n",
      "----- Episode 27 of 300\n",
      "Simulating...\n",
      "Total reward: -1854836.9044367159 - Epsilon: 0.91\n",
      "Training...\n",
      "Simulation time: 328.3 s - Training time: 242.3 s - Total: 570.6 s\n",
      "\n",
      "----- Episode 28 of 300\n",
      "Simulating...\n",
      "Total reward: -3073937.950424037 - Epsilon: 0.91\n",
      "Training...\n",
      "Simulation time: 298.6 s - Training time: 243.5 s - Total: 542.1 s\n",
      "\n",
      "----- Episode 29 of 300\n",
      "Simulating...\n",
      "Total reward: -410173.2354088912 - Epsilon: 0.91\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation time: 79.6 s - Training time: 242.7 s - Total: 322.3 s\n",
      "\n",
      "----- Episode 30 of 300\n",
      "Simulating...\n",
      "Total reward: -628952.674798204 - Epsilon: 0.9\n",
      "Training...\n",
      "Simulation time: 113.5 s - Training time: 250.7 s - Total: 364.2 s\n",
      "\n",
      "----- Episode 31 of 300\n",
      "Simulating...\n",
      "Total reward: -768324.9850593398 - Epsilon: 0.9\n",
      "Training...\n",
      "Simulation time: 157.5 s - Training time: 260.2 s - Total: 417.7 s\n",
      "\n",
      "----- Episode 32 of 300\n",
      "Simulating...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-63440f7247c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m#run simulation + train for one episode at a time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0msimulation_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# run the simulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Simulation time:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimulation_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's - Training time:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's - Total:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulation_time\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtraining_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mepisode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Deep-QLearning-Agent-for-Traffic-Signal-Control\\TLCS\\simulation.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, episode, epsilon)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[1;31m# get current state of the intersection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;31m# print(\"current_state shape: \", len(current_state))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Deep-QLearning-Agent-for-Traffic-Signal-Control\\TLCS\\simulation.py\u001b[0m in \u001b[0;36m_get_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mlane_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLanePosition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[0mlane_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLaneID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[0mlane_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m750\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlane_pos\u001b[0m  \u001b[1;31m# inversion of lane pos, so if the car is close to the traffic light -> lane_pos = 0 --- 750 = max len of a road\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\_vehicle.py\u001b[0m in \u001b[0;36mgetLaneID\u001b[1;34m(self, vehID)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mid\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlane\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnamed\u001b[0m \u001b[0mvehicle\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mat\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getUniversal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAR_LANE_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvehID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetLaneIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvehID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\domain.py\u001b[0m in \u001b[0;36m_getUniversal\u001b[1;34m(self, varID, objectID)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mFatalTraCIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Not connected.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sendReadOneStringCmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmdGetID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjectID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retValFunc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvarID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36m_sendReadOneStringCmd\u001b[1;34m(self, cmdID, varID, objID)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sendReadOneStringCmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmdID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_beginMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmdID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmdID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sendIntCmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmdID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36m_checkResult\u001b[1;34m(self, cmdID, varID, objID)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_checkResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmdID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sendExact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadLength\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretVarID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"!BB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36m_sendExact\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"!i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# print(\"python_sendExact: '%s'\" % ' '.join(map(lambda x : \"%X\" % ord(x), self._string)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recvExact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    config = import_train_configuration(config_file='training_settings.ini')\n",
    "    sumo_cmd = set_sumo(config['gui'], config['sumocfg_file_name'], config['max_steps'])\n",
    "    path = set_train_path(config['models_path_name'])\n",
    "\n",
    "    \n",
    "\n",
    "#     # SET PARAMETERS (ADD TO CONFIG LATER)\n",
    "#     #TO DO: add to config files:\n",
    "    sequence_length = 15\n",
    "    \n",
    "    #SET STATE DIMENSION PARAMETERS\n",
    "    number_of_cells_per_lane = 10\n",
    "    conv_state_shape = (number_of_cells_per_lane, 8, 2)\n",
    "    green_phase_state_shape = 4\n",
    "    elapsed_time_state_shape = 1\n",
    "    state_shape = [conv_state_shape, green_phase_state_shape, elapsed_time_state_shape]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    TrafficGen = TrafficGenerator(\n",
    "        config['max_steps'], \n",
    "        config['penetration_rate']\n",
    "    )\n",
    "\n",
    "    Visualization = Visualization(\n",
    "        path, \n",
    "        dpi=96\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #VANILLA MODEL\n",
    "    if config['uses_reccurent_network'] == False:\n",
    "        \n",
    "        # online model used for training\n",
    "        Model = VanillaTrainModel(\n",
    "            config['batch_size'], \n",
    "            config['learning_rate'], \n",
    "            output_dim=config['num_actions'],\n",
    "            state_shape=state_shape\n",
    "        )\n",
    "        Model._model.summary()\n",
    "        plot_model(Model._model, 'my_first_model_with_shape_info.png', show_shapes=True)\n",
    "\n",
    "        #target model, only used for predictions. regularly the values of Model are copied into TargetModel\n",
    "        TargetModel = VanillaTrainModel(\n",
    "            config['batch_size'], \n",
    "            config['learning_rate'], \n",
    "            output_dim=config['num_actions'],\n",
    "            state_shape=state_shape\n",
    "        )\n",
    "        \n",
    "        Memory = NormalMemory(\n",
    "            config['memory_size_max'], \n",
    "            config['memory_size_min']\n",
    "        )\n",
    "        \n",
    "        Simulation = VanillaTrainSimulation(\n",
    "            Model,\n",
    "            TargetModel,\n",
    "            Memory,\n",
    "            TrafficGen,\n",
    "            sumo_cmd,\n",
    "            config['gamma'],\n",
    "            config['max_steps'],\n",
    "            config['green_duration'],\n",
    "            config['yellow_duration'],\n",
    "            config['num_actions'],\n",
    "            config['training_epochs'],\n",
    "            config['copy_step']\n",
    "        )\n",
    "\n",
    "        \n",
    "    #RECURRENT MODEL\n",
    "    else:\n",
    "            # online model used for training\n",
    "        Model = RNNTrainModel(\n",
    "            config['batch_size'], \n",
    "            config['learning_rate'], \n",
    "            output_dim=config['num_actions'],\n",
    "            state_shape=state_shape,\n",
    "            sequence_length=sequence_length, \n",
    "            statefulness = False\n",
    "        )\n",
    "        Model._model.summary()\n",
    "        plot_model(Model._model, 'my_first_model_with_shape_info.png', show_shapes=True)\n",
    "\n",
    "\n",
    "        #target model, only used for predictions. regularly the values of Model are copied into TargetModel\n",
    "        TargetModel = RNNTrainModel( \n",
    "            config['batch_size'], \n",
    "            config['learning_rate'], \n",
    "            output_dim=config['num_actions'],\n",
    "            state_shape=state_shape,\n",
    "            sequence_length=sequence_length,\n",
    "            statefulness = False\n",
    "        )\n",
    "        \n",
    "        PredictModel = RNNTrainModel(\n",
    "            config['batch_size'], \n",
    "            config['learning_rate'], \n",
    "            output_dim=config['num_actions'],\n",
    "            state_shape=state_shape,\n",
    "            sequence_length=sequence_length,\n",
    "            statefulness = True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        Memory = SequenceMemory(\n",
    "            config['memory_size_max'], \n",
    "            config['memory_size_min'],\n",
    "            sequence_length\n",
    "        )\n",
    "        \n",
    "        Simulation = RNNTrainSimulation(\n",
    "            Model,\n",
    "            TargetModel,\n",
    "            Memory,\n",
    "            TrafficGen,\n",
    "            sumo_cmd,\n",
    "            config['gamma'],\n",
    "            config['max_steps'],\n",
    "            config['green_duration'],\n",
    "            config['yellow_duration'],\n",
    "            config['num_actions'],\n",
    "            config['training_epochs'],\n",
    "            config['copy_step'],\n",
    "            PredictModel\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('Starting...' )\n",
    "    print(' ')\n",
    "    \n",
    "    episode = 0\n",
    "    timestamp_start = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    while episode < config['total_episodes']:\n",
    "        print('\\n----- Episode', str(episode+1), 'of', str(config['total_episodes']))\n",
    "        \n",
    "        #set epsilon\n",
    "        epsilon = 1.0 - (episode / config['total_episodes'])  # set the epsilon for this episode according to epsilon-greedy policy\n",
    "        \n",
    "        \n",
    "        #run simulation + train for one episode at a time\n",
    "        simulation_time, training_time = Simulation.run(episode, epsilon)  # run the simulation\n",
    "        print('Simulation time:', simulation_time, 's - Training time:', training_time, 's - Total:', round(simulation_time+training_time, 1), 's')\n",
    "        episode += 1\n",
    "\n",
    "    print(\"\\n----- Start time:\", timestamp_start)\n",
    "    print(\"----- End time:\", datetime.datetime.now())\n",
    "    print(\"----- Session info saved at:\", path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Model.save_model(path)\n",
    "\n",
    "    copyfile(src='training_settings.ini', dst=os.path.join(path, 'training_settings.ini'))\n",
    "\n",
    "    Visualization.training_save_data_and_plot(data=Simulation.reward_store, filename='reward', xlabel='Episode', ylabel='Cumulative negative reward')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_model(Simulation._Model._model, show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
